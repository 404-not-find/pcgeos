COMMENT @MECHANISM DESCRIPTION-------------------------------------------------

			    InputFlow

$Id: InputFlow.doc,v 1.3.34.1 97/03/29 03:37:20 canavese Exp $

Synopsis
--------

	This document explains how input flow, specifically keyboard and
	mouse data, flow from device driver to specific objects within an
	application.

Limitations
-----------

Alternatives
------------
	None, really, other than intercepting info at various points along
	the chain.

Implementation Status
---------------------
	Just getting started :)

See Also
--------
	<related objects, mechanisms, modules, other documentation>

;------------------------------------------------------------------------------
;	Description
;------------------------------------------------------------------------------

Terminology
-----------

Relationships/Context
---------------------
	The key players are:
		Device Drivers
		Input Manager
		Window System
		The UI's GenSystemClass object
		Applications's GenApplicationClass objects

Conceptual Overview
-------------------
	Device drivers first send "raw" input messages to the IM thread.  The
	current such messages are:

		MSG_IM_BUTTON_CHANGE
		MSG_IM_PTR_CHANGE
		MSG_IM_KBD_SCAN

	The device drivers themselves, & the kernel, installs monitors into
	the IM to convert these to the more familiar messages:

		MSG_META_BUTTON
		MSG_META_PTR
		MSG_KBD_SCAN

	The final input monitor, on any pointer movement, calls the window
	system, to check to see if the mouse has gone outside of the current
	bounds of the window region that it was in.  If so, a MSG_META_WIN_CHANGE
	is sent to the system object to let it know of this fact.  Also, if
	there is a transition from no buttons down to any buttons down, 
	the system object is sent a MSG_GEN_SCREEN_LAYER_GRAB, instructing
	it to "grab" the mouse for the current layer.
	MSG_GEN_SCREEN_LAYER_RELEASE is sent, likewise, to the system object,
	if all mouse buttons go up.  In all cases, the input messages
	are then sent to the "output" of the IM.
	The output will initially be set to be the system object, but will,
	when circumstances allow, be redirected to deliver input straight to
	the current application object.  At any sign of need for arbitration,
	the output will be set back to the system object.  Roughly, the
	following events would be cause to start sending everything through the
	system object:

		* The mouse moving to a different window.
		* ALT-ESC, or other app-switching keyboard sequence hit.
		* A system modal dialog is on screen.
		* The system object receives MSG_GEN_SCREEN_ALLOW_GLOBAL_
		  TRANSFER

	Input could be allowed to flow directly to the application object once
	again after the above events have completed, & the UI queue emptied of
	events to process.

	The system object, meanwhile, on reciept of MSG_META_WIN_CHANGE calls
	WinChangeAck, which generates MSG_RAW_UNIV/VIS_ENTER/LEAVE messages, &
	MSG_META_IMPLIED_WIN_CHANGE, which are all sent to the system object.
	The system object then determines the "implied" layer, and knows when
	the "implied" layer has become "active", as well (due to receiving
	MSG_GEN_SCREEN_LAYER_GRAB) Note that the "active" grab is released on
	either MSG_GEN_SCREEN_LAYER_RELEASE or MSG_GEN_SCREEN_ALLOW_GLOBAL_
	TRANSFER, the latter a request by an app at the start of a quick
	transfer sequence, to let the mouse wander to another app.  The
	"active" grab is also replaced anytime a system modal dialog is
	brought up -- once this has happened, it will remain the permanent
	"active" layer until the system modal state ends (after which, the
	mouse will have to be pressed again before a new layer is made active)
	MSG_META_IMPLIED_WIN_CHANGE, by the way, is passed on to the active/implied
	app,  with the optr of the implied window NULL'd out if it does not
	belong to the active/implied layer.  App objects are sent a message
	(MSG_GEN_APP_LEAVE (?)) when they lose out to another app,
	so that they can store an implied win of NULL, & force off mouse
	grabs (in case a sys modal win has forced a switch while some object
	in the app had the mouse grabbed)

	The system object will update the window system, via WinSetActiveLayer,
	so that it will know whenever there is an "active" layer grab.  The
	window system references this only to figure out which Layer's ptr
	images should be shown.  The app, then, is responsible for setting the
	PIL_LAYER ptr image to reflect modal, busy, etc. states, depending on
	which window the mouse is over.  This behavior will be provided as
	default behavior in OLApplicationClass.

	Now, the app just sees MSG_META_IMPLIED_WIN_CHANGE, input events, &
	MSG_GEN_APP_ENTER, MSG_GEN_APP_LEAVE.  The VisContent superclass by
	default stores the new implied window, & will direct things there, 
	unless there is a grab override or the app intervenes.  The app 
	should intervene, storing NULL instead, if it has a system modal or
	app modal window up, & the mouse isn't over it.  The app should force
	release (via TAKE_GADGET_EXCL) of any mouse grab on MSG_GEN_APP_LEAVE.
	It also must set the correct ptr image for its layer, as described 
	above.

	The system will also implement the focus model at least at the 
	choosing of app level, using the "click to type" model.
	(though it could accomplish real-estate if it wanted to).  Applications
	should generally NOT request the focus/target, but instead these will
	simply be granted to them.

	Likewise, the sytem will implement the "raise" model, using "click to
	raise", though, again, it could be recoded to behave differently.
	Applications should generally NOT raise or lower their own layer.

	The system/field(?) object will perform the initial "raise" & focus
	setting on new apps as they are launched, somehow...

Warnings
--------
	Because mouse input is now processed according to the window it occurs
	over, intermixed w/enter/leave messages, & then sent to the app, the
	net effect to the user is that of interacting with what they "See",
	not what they "Do".  For example:  A quick press on a menu, drag down
	& release will not activate a menu item, if the user does all this
	before the menu comes up.  This is distinctly different from the V1.2
	model, in which window location, enter/leave events were generated 
	AS EACH INPUT EVENT was processed.  Net result:  In V1.2, the menu
	item activates in the above scenerio.  It's unclear which way is
	actually best for the user, but as the core V2.0 input changes result
	initially in the "new" model, we'll see how that works out first.

Usage: <Usage #1>
-----------------
	<Describe the common case, then exactly what the programmer has to do
	 to completely support it.  If 1 or more "In-Depth" topics apply, refer
	 to them.>

Usage: <Usage #2>
-----------------
	<If more than one common case..>

...

In-Depth: "DRAG" messages
-------------------------
Ah yes, the "DRAG" messages.  These are really cool.   Their purpose is to
allow apps to easily differentiate between a user "clicking" on something,
& trying to "drag" or "select through" something.  You see, when you "click"
on something, say to set the text insertion point, or select a window, you
almost invariably jiggle the mouse a bit, causing a START, one or more PTR's, &
an END to occur.  Thus, just tapping on the text object, or a window, would
often result in selecting small characters such as "i", or moving the window,
forcing it to completely redraw.  This is where the "DRAG" messages come in.
A single "DRAG" message is sent between "START" & "END" messages only if one
of the following two criteria are met:

        1) The mouse has been moved more than IM_DEFAULT_DRAG_DISTANCE pixels
           since it was pressed.  IM_DEFAULT_DRAG_DISTANCE is by default 10.

        2) The mouse button has been held down longer than IM_DEFAULT_DRAG_TIME
           (current value 14, i.e. 14 ticks or 14/60ths of a second.)

Thus, if you just "tap" the mouse, the app won't get a "DRAG" message, even if
the mouse was jiggled a bit.  If you click & hold, or start moving the mouse,
it will.  As a programmer, then, you don't to start drag or select operations
on either the "START" message or the first "PTR" message, but instead only on
a "DRAG" message.


In-Depth: <Topic #2>
--------------------

...


See Also
--------
	<related objects, mechanisms, modules, other documentation>

;------------------------------------------------------------------------------
;	Assembling & Debugging
;------------------------------------------------------------------------------


Sample Code/Programming Tips
----------------------------
	<useful code snippets, references to sample applications & a short
	 description of them>

Include Files Needed
--------------------

Assembly Tips
-------------

Debugging Tools & Tips
----------------------

See Also
--------
	<Sample apps, related tools, other documentation>


;------------------------------------------------------------------------------
;	Internal Structure
;------------------------------------------------------------------------------


;------------------------------------------------------------------------------
;	Most frequently asked questions
;------------------------------------------------------------------------------

	<anytime someone asks you a question about this object, clear up
	 the documentation above to explain it, or add an entry here>


;------------------------------------------------------------------------------
;	Declaration
;------------------------------------------------------------------------------

	NOTE: The section between "Declaration" and "End Declaration" is
	      copied into uilib.def by "pmake def"

Declaration
-----------

;------------------------------------------------------------------------------
;	Constants & Structures
;------------------------------------------------------------------------------

	<Use this section only for files which actually make declarations
	 relative to the mechansism, i.e. are code & not just documentation>

End Declaration
---------------

------------------------------------------------------------------------------@

>> Conceptually, how do the Drivers, Kernel, Flow object, and
>> applications (and specific UI) relate to each other when input is
>> being passed?
>> I.e., what stages does a keyboard press (and release) go through from
>> IBM keyboard to GenText object? What stages does a mouse movement go
>> through, etc.

Drivers send messages to the IM, which are then sent through all the installed
monitors.  To make things trickier, drivers sometimes install monitors
themselves.  Once through the monitor chain, the window system is called to
update any new ptr image location, and then the messages are sent to the UI
(currently the flow object, but will be changed to be either the system object, 
or directly an application object for V2.0).   From there, they go the active
application object.  From there, mouse input goes to the active grab, otherwise,
if one doesn't exist, to the object under the mouse (implied grab).  Keyboard
data goes to whoever has the KBD exclusive, (which is automatically given to
the leaf focus object).


